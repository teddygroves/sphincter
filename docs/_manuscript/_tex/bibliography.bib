@article{gelmanBayesianWorkflow2020,
  title = {Bayesian Workflow},
  author = {Gelman, Andrew and Vehtari, Aki and Simpson, Daniel and Margossian, Charles C. and Carpenter, Bob and Yao, Yuling and Kennedy, Lauren and Gabry, Jonah and B{\"u}rkner, Paul-Christian and Modr{\'a}k, Martin},
  year = {2020},
  month = {nov},
  abstract = {The Bayesian approach to data analysis provides a powerful way to handle uncertainty in all observations, model parameters, and model structure using probability theory. Probabilistic programming languages make it easier to specify and fit Bayesian models, but this still leaves us with many options regarding constructing, evaluating, and using these models, along with many remaining challenges in computation. Using Bayesian inference to solve real-world problems requires not only statistical skills, subject matter knowledge, and programming, but also awareness of the decisions made in the process of data analysis. All of these aspects can be understood as part of a tangled workflow of applied Bayesian statistics. Beyond inference, the workflow also includes iterative model building, model checking, validation and troubleshooting of computational problems, model understanding, and model comparison. We review all these aspects of workflow in the context of several examples, keeping in mind that in practice we will be fitting many models for any given problem, even if only a subset of them will ultimately be relevant for our conclusions.},
  archiveprefix = {arXiv},
  eprint = {2011.01808},
  eprinttype = {arxiv},
  file = {/Users/tedgro/Zotero/storage/XEI2Q7F4/Gelman et al. - 2020 - Bayesian Workflow.pdf;/Users/tedgro/Zotero/storage/8Y5YAYXE/2011.html},
  journal = {arXiv:2011.01808 [stat]},
  keywords = {Statistics - Methodology},
  primaryclass = {stat},
}

@article{spiegelhalterBayesianGraphicalModelling1998,
  title = {Bayesian {{Graphical Modelling}}: {{A Case-Study}} in {{Monitoring Health Outcomes}}},
  shorttitle = {Bayesian {{Graphical Modelling}}},
  author = {Spiegelhalter, David J.},
  year = {1998},
  month = mar,
  journal = {Journal of the Royal Statistical Society Series C: Applied Statistics},
  volume = {47},
  number = {1},
  pages = {115--133},
  issn = {0035-9254, 1467-9876},
  doi = {10.1111/1467-9876.00101},
  url = {https://academic.oup.com/jrsssc/article/47/1/115/6990621},
  urldate = {2023-11-03},
  abstract = {Bayesian graphical modelling represents the synthesis of several recent developments in applied complex modelling. After describing a moderately challenging real example, we show how graphical models and Markov chain Monte Carlo methods naturally provide a direct path between model speci\textregistered cation and the computational means of making inferences on that model. These ideas are illustrated with a range of modelling issues related to our example. An appendix discusses the BUGS software.},
  langid = {english},
  file = {/Users/tedgro/Zotero/storage/IP9KAM85/Spiegelhalter - 1998 - Bayesian Graphical Modelling A Case-Study in Moni.pdf}
}

@article{tornqvistHowShouldRelative1985,
  title = {How {{Should Relative Changes Be Measured}}?},
  author = {Tornqvist, Leo and Vartia, Pentti and Vartia, Yrjo O.},
  year = {1985},
  journal = {The American Statistician},
  volume = {39},
  number = {1},
  eprint = {2683905},
  eprinttype = {jstor},
  pages = {43--46},
  publisher = {{[American Statistical Association, Taylor \& Francis, Ltd.]}},
  issn = {0003-1305},
  doi = {10.2307/2683905},
  url = {https://www.jstor.org/stable/2683905},
  urldate = {2023-11-07},
  abstract = {Various indicators of relative change (or difference) are considered. It is shown that the log change defined by loge (v/x) is the only symmetric, additive, and normed indicator of relative change. It is proposed that the values of the log change in percent, 100 loge(y/x), be denoted by the symbol L\%, the log percentage. It is hoped that the symmetric and additive log percentages will gradually replace the ordinary asymmetric and nonadditive percentages.},
  file = {/Users/tedgro/Zotero/storage/2ZITCFPK/Tornqvist et al. - 1985 - How Should Relative Changes Be Measured.pdf}
}

@article{juarezModelBasedClusteringNonGaussian2010,
  title = {Model-{{Based Clustering}} of {{Non-Gaussian Panel Data Based}} on {{Skew-t Distributions}}},
  author = {Ju{\'a}rez, Miguel A. and Steel, Mark F. J.},
  year = {2010},
  month = jan,
  journal = {Journal of Business \& Economic Statistics},
  volume = {28},
  number = {1},
  pages = {52--66},
  publisher = {{Taylor \& Francis}},
  issn = {0735-0015},
  doi = {10.1198/jbes.2009.07145},
  url = {https://doi.org/10.1198/jbes.2009.07145},
  urldate = {2021-09-07},
  abstract = {We propose a model-based method to cluster units within a panel. The underlying model is autoregressive and non-Gaussian, allowing for both skewness and fat tails, and the units are clustered according to their dynamic behavior, equilibrium level, and the effect of covariates. Inference is addressed from a Bayesian perspective, and model comparison is conducted using Bayes factors. Particular attention is paid to prior elicitation and posterior propriety. We suggest priors that require little subjective input and have hierarchical structures that enhance inference robustness. We apply our methodology to GDP growth of European regions and to employment growth of Spanish firms.},
  keywords = {Autoregressive modeling,Employment growth,GDP growth convergence,Hierarchical prior,Model comparison,Posterior propriety,Skewness},
  file = {/Users/tedgro/Zotero/storage/EL3ZEJ39/Ju√°rez and Steel - 2010 - Model-Based Clustering of Non-Gaussian Panel Data .pdf;/Users/tedgro/Zotero/storage/ZFXS2WUD/jbes.2009.html}
}


@article{carpenterStanProbabilisticProgramming2017,
  title = {Stan: {{A Probabilistic Programming Language}}},
  shorttitle = {Stan},
  author = {Carpenter, Bob and Gelman, Andrew and Hoffman, Matthew D. and Lee, Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Marcus and Guo, Jiqiang and Li, Peter and Riddell, Allen},
  year = {2017},
  month = jan,
  journal = {Journal of Statistical Software},
  volume = {76},
  number = {1},
  pages = {1--32},
  issn = {1548-7660},
  doi = {10.18637/jss.v076.i01},
  url = {https://www.jstatsoft.org/index.php/jss/article/view/v076i01},
  urldate = {2020-08-27},
  copyright = {Copyright (c) 2017 Bob Carpenter, Andrew Gelman, Matthew D. Hoffman, Daniel Lee, Ben Goodrich, Michael Betancourt, Marcus Brubaker, Jiqiang Guo, Peter Li, Allen Riddell},
  langid = {english},
  keywords = {algorithmic differentiation,Bayesian inference,probabilistic programming,Stan},
  file = {/Users/tedgro/Zotero/storage/F4VI282K/Carpenter et al. - 2017 - Stan A Probabilistic Programming Language.pdf;/Users/tedgro/Zotero/storage/JNJQGTST/v076i01.html}
}

@misc{standevelopmentteamCmdStanPy2022,
  title = {{{CmdStanPy}}},
  author = {{Stan Development Team}},
  year = {2022},
  url = {https://github.com/stan-dev/cmdstanpy}
}

@article{kumarArviZUnifiedLibrary2019,
  title = {{{ArviZ}} a Unified Library for Exploratory Analysis of {{Bayesian}} Models in {{Python}}},
  author = {Kumar, Ravin and Carroll, Colin and Hartikainen, Ari and Martin, Osvaldo},
  year = {2019},
  month = jan,
  journal = {Journal of Open Source Software},
  volume = {4},
  number = {33},
  pages = {1143},
  issn = {2475-9066},
  doi = {10.21105/joss.01143},
  url = {http://joss.theoj.org/papers/10.21105/joss.01143},
  urldate = {2021-12-02},
  abstract = {While conceptually simple, Bayesian methods can be mathematically and numerically challenging. Probabilistic programming languages (PPLs) implement functions to easily build Bayesian models together with efficient automatic inference methods. This helps separate the model building from the inference, allowing practitioners to focus on their specific problems and leaving PPLs to handle the computational details for them (Bessiere, Mazer, Ahuactzin, \& Mekhnacha, 2013; Daniel Roy, 2015; Ghahramani, 2015). The inference process generates a posterior distribution \textemdash{} which has a central role in Bayesian statistics \textemdash{} together with other distributions like the posterior predictive distribution and the prior predictive distribution. The correct visualization, analysis, and interpretation of these distributions is key to properly answer the questions that motivate the inference process.},
  langid = {english},
  file = {/Users/tedgro/Zotero/storage/HT4JS7NP/Kumar et al. - 2019 - ArviZ a unified library for exploratory analysis o.pdf}
}

@software{bibat,
  doi = {10.5281/zenodo.7775328},
  url = {https://github.com/teddygroves/bibat},
  year = {2023},
  author = {Teddy Groves},
  title = {Bibat: batteries-included Bayesian analysis template},
}

@article{vehtariRankNormalizationFoldingLocalization2021,
  title = {Rank-{{Normalization}}, {{Folding}}, and {{Localization}}: {{An Improved R\textasciicircum}} for {{Assessing Convergence}} of {{MCMC}} (with {{Discussion}})},
  shorttitle = {Rank-{{Normalization}}, {{Folding}}, and {{Localization}}},
  author = {Vehtari, Aki and Gelman, Andrew and Simpson, Daniel and Carpenter, Bob and B{\"u}rkner, Paul-Christian},
  year = {2021},
  month = jun,
  journal = {Bayesian Analysis},
  volume = {16},
  number = {2},
  pages = {667--718},
  publisher = {{International Society for Bayesian Analysis}},
  issn = {1936-0975, 1931-6690},
  doi = {10.1214/20-BA1221},
  url = {https://projecteuclid.org/journals/bayesian-analysis/volume-16/issue-2/Rank-Normalization-Folding-and-Localization--An-Improved-R%cb%86-for/10.1214/20-BA1221.full},
  urldate = {2022-01-03},
  abstract = {Markov chain Monte Carlo is a key computational tool in Bayesian statistics, but it can be challenging to monitor the convergence of an iterative stochastic algorithm. In this paper we show that the convergence diagnostic R\textasciicircum{} of Gelman and Rubin (1992) has serious flaws. Traditional R\textasciicircum{} will fail to correctly diagnose convergence failures when the chain has a heavy tail or when the variance varies across the chains. In this paper we propose an alternative rank-based diagnostic that fixes these problems. We also introduce a collection of quantile-based local efficiency measures, along with a practical approach for computing Monte Carlo error estimates for quantiles. We suggest that common trace plots should be replaced with rank plots from multiple chains. Finally, we give recommendations for how these methods should be used in practice.},
  file = {/Users/tedgro/Zotero/storage/FPRAEFHZ/Vehtari et al. - 2021 - Rank-Normalization, Folding, and Localization An .pdf;/Users/tedgro/Zotero/storage/ST53UIWZ/20-BA1221.html}
}

@article{vehtariPracticalBayesianModel2017,
  title = {Practical {{Bayesian}} Model Evaluation Using Leave-One-out Cross-Validation and {{WAIC}}},
  author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
  year = {2017},
  month = sep,
  journal = {Statistics and Computing},
  volume = {27},
  number = {5},
  eprint = {1507.04544},
  pages = {1413--1432},
  issn = {0960-3174, 1573-1375},
  doi = {10.1007/s11222-016-9696-4},
  url = {http://arxiv.org/abs/1507.04544},
  urldate = {2021-02-23},
  abstract = {Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparison of predictive errors between two models. We implement the computations in an R package called loo and demonstrate using models fit with the Bayesian inference package Stan.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Statistics - Computation,Statistics - Methodology},
  file = {/Users/tedgro/Zotero/storage/554NNNS2/Vehtari et al. - 2017 - Practical Bayesian model evaluation using leave-on.pdf}
}
@misc{betancourtDiagnosingBiasedInference2017,
  title = {Diagnosing {{Biased Inference}} with {{Divergences}}},
  author = {Betancourt, Michael},
  year = {2017},
  journal = {betanalpha.github.io},
  url = {https://github.com/betanalpha/knitr_case_studies/tree/master/divergences_and_bias},
  urldate = {2023-02-13},
  langid = {english},
  annotation = {commit b474ec1a5a79347f7c9634376c866fe3294d657a},
  file = {/Users/tedgro/Zotero/storage/ZYV3R7VK/writing.html}
}
@inproceedings{niels_bantilan-proc-scipy-2020,
  title = {Pandera: {{Statistical Data Validation}} of {{Pandas Dataframes}}},
  booktitle = {Proceedings of the 19th {{Python}} in {{Science Conference}}},
  author = {{Niels Bantilan}},
  editor = {Agarwal, Meghann and Calloway, Chris and Niederhut, Dillon and {David Shupe}},
  year = {2020},
  pages = {116--124},
  doi = {10.25080/Majora-342d178e-010}
}
@misc{pydanticdevelopersPydantic2022,
  title = {Pydantic},
  author = {{Pydantic developers}},
  year = {2022},
  url = {https://pypi.org/project/pydantic/}
}

@article{piironenSparsityInformationRegularization2017,
  title = {Sparsity Information and Regularization in the Horseshoe and Other Shrinkage Priors},
  author = {Piironen, Juho and Vehtari, Aki},
  year = {2017},
  month = jan,
  journal = {Electronic Journal of Statistics},
  volume = {11},
  number = {2},
  issn = {1935-7524},
  doi = {10.1214/17-EJS1337SI},
  url = {https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-11/issue-2/Sparsity-information-and-regularization-in-the-horseshoe-and-other-shrinkage/10.1214/17-EJS1337SI.full},
  urldate = {2023-03-13},
  abstract = {The horseshoe prior has proven to be a noteworthy alternative for sparse Bayesian estimation, but has previously suffered from two problems. First, there has been no systematic way of specifying a prior for the global shrinkage hyperparameter based on the prior information about the degree of sparsity in the parameter vector. Second, the horseshoe prior has the undesired property that there is no possibility of specifying separately information about sparsity and the amount of regularization for the largest coefficients, which can be problematic with weakly identified parameters, such as the logistic regression coefficients in the case of data separation. This paper proposes solutions to both of these problems. We introduce a concept of effective number of nonzero parameters, show an intuitive way of formulating the prior for the global hyperparameter based on the sparsity assumptions, and argue that the previous default choices are dubious based on their tendency to favor solutions with more unshrunk parameters than we typically expect a priori. Moreover, we introduce a generalization to the horseshoe prior, called the regularized horseshoe, that allows us to specify a minimum level of regularization to the largest values. We show that the new prior can be considered as the continuous counterpart of the spike-and-slab prior with a finite slab width, whereas the original horseshoe resembles the spike-and-slab with an infinitely wide slab. Numerical experiments on synthetic and real world data illustrate the benefit of both of these theoretical advances.},
  langid = {english},
  file = {/Users/tedgro/Zotero/storage/ZUX4LE4Q/Piironen and Vehtari - 2017 - Sparsity information and regularization in the hor.pdf}
}

@article{gaoImprovingMultilevelRegression2019,
  title = {Improving Multilevel Regression and Poststratification with Structured Priors},
  author = {Gao, Yuxiang and Kennedy, Lauren and Simpson, Daniel and Gelman, Andrew},
  year = {2019},
  month = sep,
  journal = {arXiv:1908.06716 [stat]},
  eprint = {1908.06716},
  primaryclass = {stat},
  url = {http://arxiv.org/abs/1908.06716},
  urldate = {2020-01-09},
  abstract = {A central theme in the field of survey statistics is estimating population-level quantities through data coming from potentially non-representative samples of the population. Multilevel Regression and Poststratification (MRP), a model-based approach, is gaining traction against the traditional weighted approach for survey estimates. MRP estimates are susceptible to bias if there is an underlying structure that the methodology does not capture. This work aims to provide a new framework for specifying structured prior distributions that lead to bias reduction in MRP estimates. We use simulation studies to explore the benefit of these prior distributions and demonstrate their efficacy on non-representative US survey data. We show that structured prior distributions offer absolute bias reduction and variance reduction for posterior MRP estimates, regardless of data regime.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/Users/tedgro/Zotero/storage/953ZS9G6/Gao et al. - 2019 - Improving multilevel regression and poststratifica.pdf}
}
